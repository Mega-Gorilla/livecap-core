# LiveCap Core æ©Ÿèƒ½ä¸€è¦§

> **ä½œæˆæ—¥:** 2025-11-25
> **ç›®çš„:** ç¾åœ¨å®Ÿè£…ã•ã‚Œã¦ã„ã‚‹å…¨æ©Ÿèƒ½ã®æ£šå¸ã—ã¨ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰

---

## 1. ãƒ‘ãƒƒã‚±ãƒ¼ã‚¸æ§‹æˆ

```
livecap-core/
â”œâ”€â”€ livecap_core/           # ã‚³ã‚¢ãƒ©ã‚¤ãƒ–ãƒ©ãƒª
â”‚   â”œâ”€â”€ __init__.py         # å…¬é–‹APIã‚¨ã‚¯ã‚¹ãƒãƒ¼ãƒˆ
â”‚   â”œâ”€â”€ cli.py              # CLIãƒ»è¨ºæ–­æ©Ÿèƒ½
â”‚   â”œâ”€â”€ i18n.py             # å›½éš›åŒ–ãƒ˜ãƒ«ãƒ‘ãƒ¼
â”‚   â”œâ”€â”€ languages.py        # è¨€èªå®šç¾©
â”‚   â”œâ”€â”€ transcription_types.py  # ã‚¤ãƒ™ãƒ³ãƒˆå‹å®šç¾©
â”‚   â”œâ”€â”€ config/
â”‚   â”‚   â”œâ”€â”€ defaults.py     # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
â”‚   â”‚   â”œâ”€â”€ schema.py       # TypedDictã‚¹ã‚­ãƒ¼ãƒ
â”‚   â”‚   â””â”€â”€ validator.py    # è¨­å®šãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
â”‚   â”œâ”€â”€ resources/
â”‚   â”‚   â”œâ”€â”€ model_manager.py    # ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†
â”‚   â”‚   â”œâ”€â”€ ffmpeg_manager.py   # FFmpegãƒã‚¤ãƒŠãƒªç®¡ç†
â”‚   â”‚   â””â”€â”€ resource_locator.py # ãƒªã‚½ãƒ¼ã‚¹ãƒ‘ã‚¹è§£æ±º
â”‚   â”œâ”€â”€ transcription/
â”‚   â”‚   â””â”€â”€ file_pipeline.py    # ãƒ•ã‚¡ã‚¤ãƒ«æ–‡å­—èµ·ã“ã—ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ __init__.py
â”œâ”€â”€ engines/                # ASRã‚¨ãƒ³ã‚¸ãƒ³å®Ÿè£…
â”‚   â”œâ”€â”€ base_engine.py      # æŠ½è±¡åŸºåº•ã‚¯ãƒ©ã‚¹
â”‚   â”œâ”€â”€ engine_factory.py   # ã‚¨ãƒ³ã‚¸ãƒ³ãƒ•ã‚¡ã‚¯ãƒˆãƒª
â”‚   â”œâ”€â”€ metadata.py         # ã‚¨ãƒ³ã‚¸ãƒ³ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿
â”‚   â”œâ”€â”€ reazonspeech_engine.py
â”‚   â”œâ”€â”€ whispers2t_engine.py
â”‚   â”œâ”€â”€ parakeet_engine.py
â”‚   â”œâ”€â”€ canary_engine.py
â”‚   â””â”€â”€ voxtral_engine.py
â””â”€â”€ config/                 # è¨­å®šãƒ“ãƒ«ãƒ€ãƒ¼
    â””â”€â”€ core_config_builder.py
```

---

## 2. æ©Ÿèƒ½åˆ¥è©³ç´°

### 2.1 è¨€èªã‚µãƒãƒ¼ãƒˆ (`livecap_core.languages`)

**æ¦‚è¦:** 16è¨€èªã®ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã€è¨€èªã‚³ãƒ¼ãƒ‰æ­£è¦åŒ–ã€ã‚¨ãƒ³ã‚¸ãƒ³ãƒãƒƒãƒ”ãƒ³ã‚°

**å¯¾å¿œè¨€èª:**
- ja (æ—¥æœ¬èª), en (English), zh-CN (ç°¡ä½“ä¸­æ–‡), zh-TW (ç¹é«”ä¸­æ–‡)
- ko (í•œêµ­ì–´), de (Deutsch), fr (FranÃ§ais), es (EspaÃ±ol)
- ru (Ğ ÑƒÑÑĞºĞ¸Ğ¹), ar (Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©), pt (PortuguÃªs), it (Italiano)
- hi (à¤¹à¤¿à¤¨à¥à¤¦à¥€), nl (Nederlands)
- åœ°åŸŸãƒãƒªã‚¢ãƒ³ãƒˆ: es-ES, es-US, pt-BR

**ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰:**

```python
from livecap_core.languages import Languages, LanguageInfo

# === è¨€èªã‚³ãƒ¼ãƒ‰ã®æ­£è¦åŒ– ===
print(Languages.normalize("JA"))       # "ja"
print(Languages.normalize("zh-TW"))    # "zh-TW"ï¼ˆç¹ä½“å­—ã¯ä¿æŒï¼‰
print(Languages.normalize("zh"))       # "zh-CN"ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã¯ç°¡ä½“å­—ï¼‰
print(Languages.normalize("en-us"))    # "en"
print(Languages.normalize("auto"))     # "auto"ï¼ˆç‰¹æ®Šã‚³ãƒ¼ãƒ‰ï¼‰

# === è¨€èªæƒ…å ±ã®å–å¾— ===
info: LanguageInfo = Languages.get_info("ja")
print(f"è¡¨ç¤ºå: {info.display_name}")        # "æ—¥æœ¬èª"
print(f"è‹±èªå: {info.english_name}")        # "Japanese"
print(f"å›½æ——: {info.flag}")                  # "ğŸ‡¯ğŸ‡µ"
print(f"ISO 639-1: {info.iso639_1}")         # "ja"
print(f"Windows LCID: {hex(info.windows_lcid)}")  # "0x411"

# === è¡¨ç¤ºåã®å–å¾— ===
print(Languages.get_display_name("ja"))              # "æ—¥æœ¬èª"
print(Languages.get_display_name("ja", english=True)) # "Japanese"

# === ã‚¨ãƒ³ã‚¸ãƒ³ãƒãƒƒãƒ”ãƒ³ã‚° ===
engines = Languages.get_engines_for_language("ja")
print(engines)  # ["reazonspeech", "whispers2t_base", "whispers2t_tiny", ...]

# === ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ ===
print(Languages.is_valid("ja"))      # True
print(Languages.is_valid("invalid")) # False

# === è‡ªå‹•æ¤œå‡ºãƒ¢ãƒ¼ãƒ‰ã®åˆ¤å®š ===
print(Languages.is_auto("auto"))     # True
print(Languages.is_auto("ja"))       # False

# === ã‚µãƒãƒ¼ãƒˆè¨€èªä¸€è¦§ ===
codes = Languages.get_supported_codes()
print(codes)  # {"ja", "en", "zh-CN", "zh-TW", ...}

# === ç¿»è¨³ã‚µãƒ¼ãƒ“ã‚¹å¯¾å¿œè¨€èª ===
google_langs = Languages.get_languages_for_translation_service("google")
print(google_langs)  # [("ja", "æ—¥æœ¬èª"), ("en", "English"), ...]

# === Windows LCID ã‹ã‚‰è¨€èªã‚³ãƒ¼ãƒ‰ ===
lang = Languages.from_windows_lcid(0x0411)
print(lang)  # "ja"
```

---

### 2.2 ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã— (`livecap_core.transcription`, `livecap_core.vad`, `livecap_core.audio_sources`)

**æ¦‚è¦:** VAD ãƒ™ãƒ¼ã‚¹ã®éŸ³å£°ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ¤œå‡ºã¨ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°æ–‡å­—èµ·ã“ã—ï¼ˆPhase 1 ã§å®Ÿè£…ï¼‰

**ã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ:**
- `StreamTranscriber`: VAD + ASR çµ„ã¿åˆã‚ã›ã‚¹ãƒˆãƒªãƒ¼ãƒ å‡¦ç†
- `VADProcessor`: Silero VAD v5/v6 ãƒ™ãƒ¼ã‚¹ã®éŸ³å£°æ´»å‹•æ¤œå‡º
- `AudioSource`: éŸ³å£°å…¥åŠ›æŠ½è±¡åŒ–ï¼ˆFileSource, MicrophoneSourceï¼‰

**å¯¾å¿œãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰:**
- Silero VAD v5/v6ï¼ˆONNXï¼‰: ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ VAD ãƒãƒƒã‚¯ã‚¨ãƒ³ãƒ‰

**ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰:**

```python
from livecap_core import (
    StreamTranscriber,
    FileSource,
    MicrophoneSource,
    VADConfig,
    TranscriptionResult,
)
from engines import EngineFactory

# === åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³• ===
engine = EngineFactory.create_engine("whispers2t_base", device="cuda")
engine.load_model()

# FileSource ã‚’ä½¿ã£ãŸãƒ†ã‚¹ãƒˆ
with StreamTranscriber(engine=engine) as transcriber:
    with FileSource("audio.wav") as source:
        for result in transcriber.transcribe_sync(source):
            print(f"[{result.start_time:.2f}s] {result.text}")

# === ãƒã‚¤ã‚¯å…¥åŠ›ã‹ã‚‰ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã— ===
with StreamTranscriber(engine=engine) as transcriber:
    with MicrophoneSource(device_id=0) as mic:
        for result in transcriber.transcribe_sync(mic):
            print(f"{result.text}")

# === éåŒæœŸ API ===
import asyncio

async def realtime_transcribe():
    async with MicrophoneSource() as mic:
        transcriber = StreamTranscriber(engine=engine)
        async for result in transcriber.transcribe_async(mic):
            print(f"{result.text}")

asyncio.run(realtime_transcribe())

# === ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯æ–¹å¼ ===
transcriber = StreamTranscriber(engine=engine)
transcriber.set_callbacks(
    on_result=lambda r: print(f"[ç¢ºå®š] {r.text}"),
    on_interim=lambda r: print(f"[é€”ä¸­] {r.text}"),
)

with FileSource("audio.wav") as source:
    for chunk in source:
        transcriber.feed_audio(chunk, source.sample_rate)

final = transcriber.finalize()
transcriber.close()

# === ã‚«ã‚¹ã‚¿ãƒ  VAD è¨­å®š ===
custom_config = VADConfig(
    threshold=0.6,           # éŸ³å£°æ¤œå‡ºé–¾å€¤ï¼ˆé«˜ã‚ã«è¨­å®šï¼‰
    min_speech_ms=300,       # æœ€å°éŸ³å£°ç¶™ç¶šæ™‚é–“
    min_silence_ms=200,      # ç„¡éŸ³åˆ¤å®šæ™‚é–“
)

transcriber = StreamTranscriber(
    engine=engine,
    vad_config=custom_config,
)

# === ãƒ‡ãƒã‚¤ã‚¹ä¸€è¦§ã®å–å¾— ===
devices = MicrophoneSource.list_devices()
for dev in devices:
    default_mark = " (default)" if dev.is_default else ""
    print(f"{dev.index}: {dev.name}{default_mark}")
```

---

### 2.3 ãƒ•ã‚¡ã‚¤ãƒ«æ–‡å­—èµ·ã“ã—ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ (`livecap_core.transcription`)

**æ¦‚è¦:** éŸ³å£°/å‹•ç”»ãƒ•ã‚¡ã‚¤ãƒ«ã®æ–‡å­—èµ·ã“ã—ã¨SRTå­—å¹•ç”Ÿæˆ

**å¯¾å¿œãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ:** .wav, .flac, .mp3, .m4a, .aac, .ogg, .wma, .opus + FFmpegã§å¤‰æ›å¯èƒ½ãªå‹•ç”»

**ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰:**

```python
from pathlib import Path
from livecap_core import (
    FileTranscriptionPipeline,
    FileTranscriptionProgress,
    FileProcessingResult,
    FileSubtitleSegment,
    FileTranscriptionCancelled,
)
from livecap_core.config import get_default_config
import numpy as np

# === åŸºæœ¬çš„ãªä½¿ç”¨æ–¹æ³• ===
def simple_transcriber(audio_data: np.ndarray, sample_rate: int) -> str:
    """éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã‚’å—ã‘å–ã‚Šã€æ–‡å­—èµ·ã“ã—çµæœã‚’è¿”ã™ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯"""
    # å®Ÿéš›ã«ã¯ASRã‚¨ãƒ³ã‚¸ãƒ³ã‚’å‘¼ã³å‡ºã™
    return "æ–‡å­—èµ·ã“ã—çµæœ"

config = get_default_config()
pipeline = FileTranscriptionPipeline(config=config)

try:
    result = pipeline.process_file(
        file_path=Path("audio.wav"),
        segment_transcriber=simple_transcriber,
    )

    print(f"æˆåŠŸ: {result.success}")
    print(f"å‡ºåŠ›ãƒ‘ã‚¹: {result.output_path}")  # audio.srt

    for segment in result.subtitles:
        print(f"{segment.start:.2f}-{segment.end:.2f}: {segment.text}")
finally:
    pipeline.close()

# === é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ä»˜ã ===
def on_progress(progress: FileTranscriptionProgress):
    print(f"[{progress.current}/{progress.total}] {progress.status}")
    if progress.context:
        print(f"  è©³ç´°: {progress.context}")

result = pipeline.process_file(
    file_path=Path("audio.wav"),
    segment_transcriber=simple_transcriber,
    progress_callback=on_progress,
)

# === è¤‡æ•°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç† ===
def on_status(message: str):
    print(f"ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹: {message}")

def on_result(result: FileProcessingResult):
    print(f"å®Œäº†: {result.source_path} - {'æˆåŠŸ' if result.success else 'å¤±æ•—'}")

def on_error(message: str, exception: Exception):
    print(f"ã‚¨ãƒ©ãƒ¼: {message}")

# ã‚­ãƒ£ãƒ³ã‚»ãƒ«åˆ¶å¾¡
cancel_flag = False
def should_cancel() -> bool:
    return cancel_flag

results = pipeline.process_files(
    file_paths=[Path("audio1.wav"), Path("audio2.mp3"), Path("video.mp4")],
    segment_transcriber=simple_transcriber,
    progress_callback=on_progress,
    status_callback=on_status,
    result_callback=on_result,
    error_callback=on_error,
    should_cancel=should_cancel,
    write_subtitles=True,
)

# === ã‚«ã‚¹ã‚¿ãƒ ã‚»ã‚°ãƒ¡ãƒ³ã‚¿ãƒ¼ ===
from typing import List, Tuple

def custom_segmenter(audio: np.ndarray, sample_rate: int) -> List[Tuple[float, float]]:
    """éŸ³å£°ã‚’ã‚»ã‚°ãƒ¡ãƒ³ãƒˆã«åˆ†å‰²ã™ã‚‹ã‚«ã‚¹ã‚¿ãƒ é–¢æ•°"""
    duration = len(audio) / sample_rate
    # 5ç§’ã”ã¨ã«ã‚»ã‚°ãƒ¡ãƒ³ãƒˆåŒ–
    segments = []
    for start in range(0, int(duration), 5):
        end = min(start + 5, duration)
        segments.append((float(start), float(end)))
    return segments

pipeline_with_segmenter = FileTranscriptionPipeline(
    config=config,
    segmenter=custom_segmenter,
)

# === ã‚­ãƒ£ãƒ³ã‚»ãƒ«å‡¦ç† ===
try:
    result = pipeline.process_file(
        file_path=Path("long_audio.wav"),
        segment_transcriber=simple_transcriber,
        should_cancel=lambda: True,  # å³åº§ã«ã‚­ãƒ£ãƒ³ã‚»ãƒ«
    )
except FileTranscriptionCancelled:
    print("å‡¦ç†ãŒã‚­ãƒ£ãƒ³ã‚»ãƒ«ã•ã‚Œã¾ã—ãŸ")
```

---

### 2.3 ASRã‚¨ãƒ³ã‚¸ãƒ³ (`engines`)

**æ¦‚è¦:** è¤‡æ•°ã®ASRã‚¨ãƒ³ã‚¸ãƒ³ã‚’çµ±ä¸€ã‚¤ãƒ³ã‚¿ãƒ¼ãƒ•ã‚§ãƒ¼ã‚¹ã§æä¾›

**åˆ©ç”¨å¯èƒ½ãªã‚¨ãƒ³ã‚¸ãƒ³:**

| ã‚¨ãƒ³ã‚¸ãƒ³ID | ãƒ¢ãƒ‡ãƒ«å | ã‚µã‚¤ã‚º | å¯¾å¿œè¨€èª |
|-----------|---------|--------|---------|
| `reazonspeech` | ReazonSpeech K2 v2 | 159MB | ja |
| `parakeet` | Parakeet TDT 0.6B v2 | 1.2GB | en |
| `parakeet_ja` | Parakeet TDT CTC 0.6B JA | 600MB | ja |
| `canary` | Canary 1B Flash | 1.5GB | en, de, fr, es |
| `voxtral` | Voxtral Mini 3B | 3GB | en, es, fr, pt, hi, de, nl, it |
| `whispers2t_tiny` | Whisper Tiny | 39MB | 13è¨€èª |
| `whispers2t_base` | Whisper Base | 74MB | 13è¨€èª |
| `whispers2t_small` | Whisper Small | 244MB | 13è¨€èª |
| `whispers2t_medium` | Whisper Medium | 769MB | 13è¨€èª |
| `whispers2t_large_v3` | Whisper Large-v3 | 1.55GB | 13è¨€èª |

**ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰:**

```python
from engines import EngineFactory, BaseEngine
from engines.metadata import EngineMetadata, EngineInfo
from livecap_core.config import get_default_config
import numpy as np

# === ã‚¨ãƒ³ã‚¸ãƒ³ã®ä½œæˆã¨ä½¿ç”¨ ===
config = get_default_config()

# ã‚¨ãƒ³ã‚¸ãƒ³ã‚’ä½œæˆ
engine = EngineFactory.create_engine(
    engine_type="whispers2t_base",
    device="cuda",  # ã¾ãŸã¯ "cpu"
    config=config,
)

# é€²æ—ã‚³ãƒ¼ãƒ«ãƒãƒƒã‚¯ã®è¨­å®š
def on_model_progress(percent: int, message: str):
    print(f"[{percent}%] {message}")

engine.set_progress_callback(on_model_progress)

# ãƒ¢ãƒ‡ãƒ«ã®ãƒ­ãƒ¼ãƒ‰
engine.load_model()

# éŸ³å£°ãƒ‡ãƒ¼ã‚¿ã®æ–‡å­—èµ·ã“ã—
audio_data = np.zeros(16000, dtype=np.float32)  # 1ç§’ã®ç„¡éŸ³
sample_rate = 16000

text, confidence = engine.transcribe(audio_data, sample_rate)
print(f"çµæœ: {text} (ç¢ºä¿¡åº¦: {confidence:.2f})")

# ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
engine.cleanup()

# === è‡ªå‹•ã‚¨ãƒ³ã‚¸ãƒ³é¸æŠ ===
config["transcription"]["engine"] = "auto"
config["transcription"]["input_language"] = "ja"

engine = EngineFactory.create_engine(
    engine_type="auto",
    device="cuda",
    config=config,
)
# æ—¥æœ¬èªã®å ´åˆã€reazonspeechãŒè‡ªå‹•é¸æŠã•ã‚Œã‚‹

# === åˆ©ç”¨å¯èƒ½ãªã‚¨ãƒ³ã‚¸ãƒ³æƒ…å ± ===
available = EngineFactory.get_available_engines()
for engine_id, info in available.items():
    print(f"{engine_id}: {info['name']} - {info['description']}")

# ç‰¹å®šã‚¨ãƒ³ã‚¸ãƒ³ã®æƒ…å ±
info = EngineFactory.get_engine_info("whispers2t_base")
print(f"åå‰: {info['name']}")
print(f"èª¬æ˜: {info['description']}")
print(f"å¯¾å¿œè¨€èª: {info['supported_languages']}")

# è¨€èªåˆ¥ã‚¨ãƒ³ã‚¸ãƒ³ä¸€è¦§
ja_engines = EngineFactory.get_engines_for_language("ja")
print(f"æ—¥æœ¬èªå¯¾å¿œ: {list(ja_engines.keys())}")

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆã‚¨ãƒ³ã‚¸ãƒ³ã®å–å¾—
default_en = EngineFactory.get_default_engine_for_language("en", config)
print(f"è‹±èªã®ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ: {default_en}")

# === ã‚¨ãƒ³ã‚¸ãƒ³ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã®ç›´æ¥ã‚¢ã‚¯ã‚»ã‚¹ ===
metadata: EngineInfo = EngineMetadata.get("reazonspeech")
print(f"ID: {metadata.id}")
print(f"è¡¨ç¤ºå: {metadata.display_name}")
print(f"ã‚µã‚¤ã‚º: {metadata.model_size}")
print(f"ãƒ‡ãƒã‚¤ã‚¹: {metadata.device_support}")
print(f"ã‚¹ãƒˆãƒªãƒ¼ãƒŸãƒ³ã‚°: {metadata.streaming}")

# å…¨ã‚¨ãƒ³ã‚¸ãƒ³å–å¾—
all_engines = EngineMetadata.get_all()
for eid, einfo in all_engines.items():
    print(f"{eid}: {einfo.display_name}")

# è¨€èªåˆ¥ã‚¨ãƒ³ã‚¸ãƒ³ãƒªã‚¹ãƒˆ
ja_engines = EngineMetadata.get_engines_for_language("ja")
print(f"æ—¥æœ¬èªå¯¾å¿œ: {ja_engines}")
```

---

### 2.4 è¨­å®šç®¡ç† (`livecap_core.config`)

**æ¦‚è¦:** ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã€ãƒãƒ¼ã‚¸ã€ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³

**ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰:**

```python
from livecap_core.config import (
    DEFAULT_CONFIG,
    get_default_config,
    merge_config,
    ConfigValidator,
    ValidationError,
)
from config import build_core_config

# === ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã®å–å¾— ===
config = get_default_config()  # ãƒ‡ã‚£ãƒ¼ãƒ—ã‚³ãƒ”ãƒ¼ã‚’è¿”ã™

# è¨­å®šã®ã‚»ã‚¯ã‚·ãƒ§ãƒ³
print(config["audio"]["sample_rate"])           # 16000
print(config["transcription"]["engine"])         # "auto"
print(config["transcription"]["input_language"]) # "ja"
print(config["translation"]["enabled"])          # False

# === è¨­å®šã®ãƒãƒ¼ã‚¸ ===
user_config = {
    "transcription": {
        "engine": "whispers2t_base",
        "input_language": "en",
    },
    "translation": {
        "enabled": True,
        "target_language": "ja",
    },
}

merged = merge_config(get_default_config(), user_config)
print(merged["transcription"]["engine"])  # "whispers2t_base"
print(merged["audio"]["sample_rate"])     # 16000ï¼ˆãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã‚’ç¶™æ‰¿ï¼‰

# === GUIè¨­å®šã‹ã‚‰Coreè¨­å®šã¸ã®å¤‰æ› ===
gui_config = {
    "transcription": {
        "engine": "reazonspeech",
    },
    "translation": {
        "enable_translation": True,  # GUIå½¢å¼ã®ã‚­ãƒ¼
        "translation_service": "google",
    },
}

core_config = build_core_config(gui_config)
# ã‚­ãƒ¼ãŒæ­£è¦åŒ–ã•ã‚Œã‚‹: enable_translation â†’ enabled
print(core_config["translation"]["enabled"])  # True
print(core_config["translation"]["service"])  # "google"

# === è¨­å®šãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ ===
errors = ConfigValidator.validate(config)
if errors:
    for err in errors:
        print(f"{err.path}: {err.message}")
else:
    print("è¨­å®šã¯æœ‰åŠ¹ã§ã™")

# ä¾‹å¤–ã‚’æŠ•ã’ã‚‹ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³
try:
    ConfigValidator.validate_or_raise(config)
except ValueError as e:
    print(f"ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ã‚¨ãƒ©ãƒ¼: {e}")

# === ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã®æ§‹é€  ===
"""
DEFAULT_CONFIG = {
    "audio": {
        "sample_rate": 16000,
        "chunk_duration": 0.25,
        "input_device": None,
        "processing": {...}
    },
    "multi_source": {
        "max_sources": 3,
        "defaults": {...},
        "sources": {}
    },
    "silence_detection": {
        "vad_threshold": 0.5,
        "vad_min_speech_duration_ms": 250,
        ...
    },
    "transcription": {
        "device": None,
        "engine": "auto",
        "input_language": "ja",
        "language_engines": {...},
        "reazonspeech_config": {...}
    },
    "translation": {
        "enabled": False,
        "service": "google",
        "target_language": "en",
        ...
    },
    "engines": {...},
    "logging": {...},
    "queue": {...},
    "debug": {...},
    "file_mode": {...}
}
"""
```

---

### 2.5 ãƒªã‚½ãƒ¼ã‚¹ç®¡ç† (`livecap_core.resources`)

**æ¦‚è¦:** ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ã€FFmpegãƒã‚¤ãƒŠãƒªã€ãƒªã‚½ãƒ¼ã‚¹ãƒ‘ã‚¹ã®ç®¡ç†

**ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰:**

```python
from livecap_core.resources import (
    ModelManager,
    FFmpegManager,
    FFmpegNotFoundError,
    ResourceLocator,
    get_model_manager,
    get_ffmpeg_manager,
    get_resource_locator,
    reset_resource_managers,
)

# === ModelManager: ãƒ¢ãƒ‡ãƒ«ã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç† ===
model_manager = get_model_manager()

# ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªãƒ‘ã‚¹
print(f"ãƒ¢ãƒ‡ãƒ«ãƒ«ãƒ¼ãƒˆ: {model_manager.models_root}")
print(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ«ãƒ¼ãƒˆ: {model_manager.cache_root}")

# ã‚¨ãƒ³ã‚¸ãƒ³å›ºæœ‰ã®ãƒ¢ãƒ‡ãƒ«ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
whisper_dir = model_manager.get_models_dir("whispers2t")
print(f"Whisperãƒ¢ãƒ‡ãƒ«: {whisper_dir}")

# ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª
temp_dir = model_manager.get_temp_dir("processing")
print(f"ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {temp_dir}")

# ãƒ•ã‚¡ã‚¤ãƒ«ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
def on_progress(downloaded: int, total: int):
    percent = (downloaded / total * 100) if total > 0 else 0
    print(f"ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ä¸­: {percent:.1f}%")

downloaded_path = model_manager.download_file(
    url="https://example.com/model.bin",
    filename="model.bin",
    expected_sha256="abc123...",  # ã‚ªãƒ—ã‚·ãƒ§ãƒ³
    progress_callback=on_progress,
)

# éåŒæœŸãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰
import asyncio

async def download_async():
    path = await model_manager.download_file_async(
        url="https://example.com/model.bin",
        filename="model.bin",
    )
    return path

# ä¸€æ™‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã‚³ãƒ³ãƒ†ã‚­ã‚¹ãƒˆãƒãƒãƒ¼ã‚¸ãƒ£
with model_manager.temporary_directory("extraction") as temp:
    # tempã¯è‡ªå‹•çš„ã«ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—ã•ã‚Œã‚‹
    print(f"ä¸€æ™‚ä½œæ¥­ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª: {temp}")

# HuggingFaceã‚­ãƒ£ãƒƒã‚·ãƒ¥ç®¡ç†
with model_manager.huggingface_cache() as cache_dir:
    # HF_HOMEãŒè‡ªå‹•è¨­å®šã•ã‚Œã‚‹
    print(f"HFã‚­ãƒ£ãƒƒã‚·ãƒ¥: {cache_dir}")

# === FFmpegManager: FFmpegãƒã‚¤ãƒŠãƒªç®¡ç† ===
ffmpeg_manager = get_ffmpeg_manager()

# FFmpegã®æ¤œç´¢
try:
    ffmpeg_path = ffmpeg_manager.resolve_executable()
    print(f"FFmpeg: {ffmpeg_path}")
except FFmpegNotFoundError:
    print("FFmpegãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

# FFprobeã®æ¤œç´¢
ffprobe_path = ffmpeg_manager.resolve_probe()
print(f"FFprobe: {ffprobe_path}")

# FFmpegã®ç¢ºä¿ï¼ˆå¿…è¦ãªã‚‰ãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼‰
ffmpeg_path = ffmpeg_manager.ensure_executable()
print(f"FFmpegç¢ºä¿: {ffmpeg_path}")

# éåŒæœŸç‰ˆ
async def ensure_async():
    path = await ffmpeg_manager.ensure_executable_async()
    return path

# ç’°å¢ƒè¨­å®šï¼ˆPATHã«è¿½åŠ ï¼‰
ffmpeg_path = ffmpeg_manager.configure_environment()
print(f"ç’°å¢ƒè¨­å®šå®Œäº†: {ffmpeg_path}")

# === ResourceLocator: ãƒªã‚½ãƒ¼ã‚¹ãƒ‘ã‚¹è§£æ±º ===
locator = get_resource_locator()

try:
    bin_path = locator.resolve("ffmpeg-bin")
    print(f"FFmpegãƒã‚¤ãƒŠãƒª: {bin_path}")
except FileNotFoundError:
    print("ãƒªã‚½ãƒ¼ã‚¹ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")

# === ã‚·ãƒ³ã‚°ãƒ«ãƒˆãƒ³ã®ãƒªã‚»ãƒƒãƒˆï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰ ===
reset_resource_managers()
```

---

### 2.6 ã‚¤ãƒ™ãƒ³ãƒˆã‚·ã‚¹ãƒ†ãƒ  (`livecap_core.transcription_types`)

**æ¦‚è¦:** æ–‡å­—èµ·ã“ã—çµæœã€ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã€ã‚¨ãƒ©ãƒ¼ç­‰ã®ã‚¤ãƒ™ãƒ³ãƒˆå‹å®šç¾©

**ã‚¤ãƒ™ãƒ³ãƒˆå‹:**
- `TranscriptionEventDict`: æ–‡å­—èµ·ã“ã—çµæœ
- `StatusEventDict`: ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹å¤‰æ›´
- `ErrorEventDict`: ã‚¨ãƒ©ãƒ¼é€šçŸ¥
- `TranslationRequestEventDict`: ç¿»è¨³ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
- `TranslationResultEventDict`: ç¿»è¨³çµæœ
- `SubtitleEventDict`: å­—å¹•é€ä¿¡

**ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰:**

```python
from livecap_core import (
    create_transcription_event,
    create_status_event,
    create_error_event,
    create_translation_request_event,
    create_translation_result_event,
    create_subtitle_event,
    validate_event_dict,
    get_event_type_name,
    normalize_to_event_dict,
    format_event_summary,
)

# === ã‚¤ãƒ™ãƒ³ãƒˆä½œæˆ ===

# æ–‡å­—èµ·ã“ã—ã‚¤ãƒ™ãƒ³ãƒˆ
transcription = create_transcription_event(
    text="ã“ã‚“ã«ã¡ã¯",
    source_id="source1",
    is_final=True,
    confidence=0.95,
    language="ja",
)
print(transcription)
# {'event_type': 'transcription', 'text': 'ã“ã‚“ã«ã¡ã¯', 'source_id': 'source1',
#  'is_final': True, 'timestamp': 1732..., 'confidence': 0.95, 'language': 'ja', 'phase': 'final'}

# ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ã‚¤ãƒ™ãƒ³ãƒˆ
status = create_status_event(
    status_code="ready",
    message="ã‚¨ãƒ³ã‚¸ãƒ³æº–å‚™å®Œäº†",
    source_id="source1",
    phase="ready",
)
print(status)

# ã‚¨ãƒ©ãƒ¼ã‚¤ãƒ™ãƒ³ãƒˆ
error = create_error_event(
    error_code="MODEL_LOAD_FAILED",
    message="ãƒ¢ãƒ‡ãƒ«ã®èª­ã¿è¾¼ã¿ã«å¤±æ•—ã—ã¾ã—ãŸ",
    source_id="source1",
    error_details="è©³ç´°ãªã‚¨ãƒ©ãƒ¼æƒ…å ±...",
)
print(error)

# ç¿»è¨³ãƒªã‚¯ã‚¨ã‚¹ãƒˆ
translation_req = create_translation_request_event(
    text="ã“ã‚“ã«ã¡ã¯",
    source_id="source1",
    source_language="ja",
    target_language="en",
)
print(translation_req)

# ç¿»è¨³çµæœ
translation_result = create_translation_result_event(
    original_text="ã“ã‚“ã«ã¡ã¯",
    translated_text="Hello",
    source_id="source1",
    source_language="ja",
    target_language="en",
    confidence=0.98,
)
print(translation_result)

# å­—å¹•ã‚¤ãƒ™ãƒ³ãƒˆ
subtitle = create_subtitle_event(
    text="ã“ã‚“ã«ã¡ã¯",
    source_id="source1",
    destination="obs",  # "obs" or "vrchat"
    is_translated=False,
)
print(subtitle)

# === ãƒãƒªãƒ‡ãƒ¼ã‚·ãƒ§ãƒ³ ===
is_valid = validate_event_dict(transcription)
print(f"æœ‰åŠ¹: {is_valid}")  # True

# === ãƒ¦ãƒ¼ãƒ†ã‚£ãƒªãƒ†ã‚£ ===
event_type = get_event_type_name(transcription)
print(f"ã‚¤ãƒ™ãƒ³ãƒˆã‚¿ã‚¤ãƒ—: {event_type}")  # "transcription"

summary = format_event_summary(transcription)
print(f"ã‚µãƒãƒªãƒ¼: {summary}")  # "[source1] Final: ã“ã‚“ã«ã¡ã¯..."

# å¤ã„å½¢å¼ã®æ­£è¦åŒ–
old_format = {"text": "ãƒ†ã‚¹ãƒˆ", "source_id": "src1"}
normalized = normalize_to_event_dict(old_format)
print(normalized)  # event_typeç­‰ãŒè¿½åŠ ã•ã‚Œã‚‹
```

---

### 2.7 CLIãƒ»è¨ºæ–­ (`livecap_core.cli`)

**æ¦‚è¦:** ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ã‹ã‚‰ã®è¨ºæ–­ã¨è¨­å®šãƒ€ãƒ³ãƒ—

**ã‚³ãƒãƒ³ãƒ‰ãƒ©ã‚¤ãƒ³ä½¿ç”¨æ³•:**

```bash
# åŸºæœ¬è¨ºæ–­
python -m livecap_core

# JSONå½¢å¼ã§å‡ºåŠ›
python -m livecap_core --as-json

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®šã‚’å‡ºåŠ›
python -m livecap_core --dump-config

# FFmpegã‚’ç¢ºä¿ï¼ˆãƒ€ã‚¦ãƒ³ãƒ­ãƒ¼ãƒ‰ï¼‰
python -m livecap_core --ensure-ffmpeg
```

**ãƒ—ãƒ­ã‚°ãƒ©ãƒ çš„ä½¿ç”¨:**

```python
from livecap_core.cli import diagnose, DiagnosticReport, main
from livecap_core.config import get_default_config

# è¨ºæ–­ã®å®Ÿè¡Œ
report: DiagnosticReport = diagnose(
    ensure_ffmpeg=False,
    config=get_default_config(),
)

print(f"è¨­å®šæœ‰åŠ¹: {report.config_valid}")
print(f"è¨­å®šã‚¨ãƒ©ãƒ¼: {report.config_errors}")
print(f"ãƒ¢ãƒ‡ãƒ«ãƒ«ãƒ¼ãƒˆ: {report.models_root}")
print(f"ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ«ãƒ¼ãƒˆ: {report.cache_root}")
print(f"FFmpegãƒ‘ã‚¹: {report.ffmpeg_path}")
print(f"i18nãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ•°: {report.i18n.fallback_count}")

# JSONå‡ºåŠ›
json_output = report.to_json()
print(json_output)

# ãƒ—ãƒ­ã‚°ãƒ©ãƒ ã‹ã‚‰CLIã‚’å®Ÿè¡Œ
exit_code = main(["--dump-config"])
```

---

### 2.8 å›½éš›åŒ– (`livecap_core.i18n`)

**æ¦‚è¦:** ç¿»è¨³é–¢æ•°ã®ç™»éŒ²ã¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸ç®¡ç†

**ã‚µãƒ³ãƒ—ãƒ«ã‚³ãƒ¼ãƒ‰:**

```python
from livecap_core.i18n import (
    translate,
    register_translator,
    register_fallbacks,
    diagnose,
    I18nManager,
)

# === ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã®ç™»éŒ² ===
register_fallbacks({
    "status.loading": "èª­ã¿è¾¼ã¿ä¸­...",
    "status.ready": "æº–å‚™å®Œäº†",
    "error.model_not_found": "ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {model_name}",
})

# ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ã‚’ä½¿ã£ãŸç¿»è¨³
message = translate("status.loading")
print(message)  # "èª­ã¿è¾¼ã¿ä¸­..."

# ãƒ—ãƒ¬ãƒ¼ã‚¹ãƒ›ãƒ«ãƒ€ãƒ¼ä»˜ã
message = translate("error.model_not_found", model_name="whispers2t")
print(message)  # "ãƒ¢ãƒ‡ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: whispers2t"

# æœªç™»éŒ²ã‚­ãƒ¼ã¯ã‚­ãƒ¼è‡ªä½“ã‚’è¿”ã™
message = translate("unknown.key")
print(message)  # "unknown.key"

# ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆå€¤ã®æŒ‡å®š
message = translate("unknown.key", default="ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸")
print(message)  # "ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆãƒ¡ãƒƒã‚»ãƒ¼ã‚¸"

# === ã‚«ã‚¹ã‚¿ãƒ ç¿»è¨³é–¢æ•°ã®ç™»éŒ² ===
def my_translator(key: str, **kwargs) -> str:
    translations = {
        "status.loading": "Loading...",
        "status.ready": "Ready",
    }
    return translations.get(key, key)

register_translator(
    my_translator,
    name="MyTranslator",
    extras=["en", "ja"],
    metadata={"version": "1.0"},
)

# ç™»éŒ²å¾Œã¯ã‚«ã‚¹ã‚¿ãƒ ç¿»è¨³é–¢æ•°ãŒå„ªå…ˆã•ã‚Œã‚‹
message = translate("status.ready")
print(message)  # "Ready"

# === è¨ºæ–­æƒ…å ± ===
diagnostics = diagnose()
print(f"ç¿»è¨³é–¢æ•°ç™»éŒ²æ¸ˆã¿: {diagnostics.translator.registered}")
print(f"ç¿»è¨³é–¢æ•°å: {diagnostics.translator.name}")
print(f"ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯æ•°: {diagnostics.fallback_count}")
```

---

## 3. ç’°å¢ƒå¤‰æ•°

| å¤‰æ•°å | èª¬æ˜ | ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆ |
|--------|------|-----------|
| `LIVECAP_CORE_MODELS_DIR` | ãƒ¢ãƒ‡ãƒ«ä¿å­˜ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | `~/.cache/LiveCap/PineLab/models` |
| `LIVECAP_CORE_CACHE_DIR` | ã‚­ãƒ£ãƒƒã‚·ãƒ¥ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | `~/.cache/LiveCap/PineLab/cache` |
| `LIVECAP_FFMPEG_BIN` | FFmpegãƒã‚¤ãƒŠãƒªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒª | è‡ªå‹•æ¤œå‡º |

---

## 4. ä¾å­˜é–¢ä¿‚ã¨ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«

```bash
# åŸºæœ¬ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«
pip install livecap-core

# ç¿»è¨³ã‚µãƒãƒ¼ãƒˆä»˜ã
pip install livecap-core[translation]

# é–‹ç™ºãƒ„ãƒ¼ãƒ«ä»˜ã
pip install livecap-core[dev]

# PyTorchã‚¨ãƒ³ã‚¸ãƒ³ä»˜ãï¼ˆReazonSpeech, Whisperï¼‰
pip install livecap-core[engines-torch]

# NeMoã‚¨ãƒ³ã‚¸ãƒ³ä»˜ãï¼ˆParakeet, Canaryï¼‰
pip install livecap-core[engines-nemo]
```

---

## 5. çµ±åˆä½¿ç”¨ä¾‹

### 5.1 ãƒ•ã‚¡ã‚¤ãƒ«æ–‡å­—èµ·ã“ã—å®Œå…¨ä¾‹

```python
from pathlib import Path
from livecap_core import FileTranscriptionPipeline, FileTranscriptionProgress
from livecap_core.config import get_default_config, merge_config
from engines import EngineFactory

# è¨­å®šã®æº–å‚™
user_config = {
    "transcription": {
        "engine": "whispers2t_base",
        "input_language": "ja",
    },
}
config = merge_config(get_default_config(), user_config)

# ã‚¨ãƒ³ã‚¸ãƒ³ã®åˆæœŸåŒ–
engine = EngineFactory.create_engine(
    engine_type=config["transcription"]["engine"],
    device="cuda",
    config=config,
)

def on_model_progress(percent: int, message: str):
    print(f"ãƒ¢ãƒ‡ãƒ«èª­è¾¼: [{percent}%] {message}")

engine.set_progress_callback(on_model_progress)
engine.load_model()

# æ–‡å­—èµ·ã“ã—é–¢æ•°ã®å®šç¾©
def transcriber(audio_data, sample_rate):
    text, confidence = engine.transcribe(audio_data, sample_rate)
    return text

# ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã®å®Ÿè¡Œ
def on_progress(progress: FileTranscriptionProgress):
    print(f"å‡¦ç†ä¸­: [{progress.current}/{progress.total}] {progress.status}")

pipeline = FileTranscriptionPipeline(config=config)

try:
    result = pipeline.process_file(
        file_path=Path("interview.mp4"),
        segment_transcriber=transcriber,
        progress_callback=on_progress,
    )

    if result.success:
        print(f"å­—å¹•ãƒ•ã‚¡ã‚¤ãƒ«: {result.output_path}")
        print(f"ã‚»ã‚°ãƒ¡ãƒ³ãƒˆæ•°: {len(result.subtitles)}")
        print(f"éŸ³å£°é•·: {result.metadata['duration_seconds']:.2f}ç§’")
    else:
        print(f"ã‚¨ãƒ©ãƒ¼: {result.error}")
finally:
    pipeline.close()
    engine.cleanup()
```

---

## 6. æœªå®Ÿè£…ãƒ»å°†æ¥ã®æ©Ÿèƒ½

ä»¥ä¸‹ã®æ©Ÿèƒ½ã¯ä»•æ§˜æ›¸ã«è¨˜è¼‰ãŒã‚ã‚‹ãŒã€ç¾æ™‚ç‚¹ã§å®Ÿè£…çŠ¶æ³ã®ç¢ºèªãŒå¿…è¦:

1. ~~**ãƒªã‚¢ãƒ«ã‚¿ã‚¤ãƒ æ–‡å­—èµ·ã“ã—**~~ â†’ **Phase 1 ã§å®Ÿè£…å®Œäº†** (Section 2.2 å‚ç…§)
2. **ç¿»è¨³ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³çµ±åˆ** - `translation`è¨­å®šã¯å­˜åœ¨ã™ã‚‹ãŒã€ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³ã¨ã®çµ±åˆè©³ç´°æœªç¢ºèª
3. **PyPIå…¬é–‹** - `pip install livecap-core`ã¯è¨˜è¼‰ã•ã‚Œã¦ã„ã‚‹ãŒæœªå…¬é–‹
4. **SystemAudioSource** - Windows WASAPI / Linux PulseAudio ã«ã‚ˆã‚‹ã‚·ã‚¹ãƒ†ãƒ éŸ³å£°ã‚­ãƒ£ãƒ—ãƒãƒ£ï¼ˆPhase 2 ä»¥é™ï¼‰
5. **æŠ•æ©Ÿçš„å®Ÿè¡Œï¼ˆSpeculativeTranscriberï¼‰** - ä½é…å»¶åŒ–ã®ãŸã‚ã®æŠ•æ©Ÿçš„æ–‡å­—èµ·ã“ã—ï¼ˆPhase 2 ä»¥é™ï¼‰
