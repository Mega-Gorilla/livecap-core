name: Integration Tests

on:
  workflow_dispatch:
  schedule:
    - cron: "0 3 * * 1"  # Weekly on Mondays at 03:00 UTC

jobs:
  transcription-pipeline:
    strategy:
      fail-fast: false
      matrix:
        # Include both hosted and self-hosted runners
        os: [ubuntu-latest, [self-hosted, linux], [self-hosted, windows]]
        
    runs-on: ${{ matrix.os }}
    
    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python
        if: matrix.os == 'ubuntu-latest'
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Set up uv
        uses: astral-sh/setup-uv@v3

      # Standard cache for hosted runners (Self-hosted optimization applied in engine-smoke-gpu)
      - name: Cache ffmpeg-bin
        if: matrix.os == 'ubuntu-latest'
        uses: actions/cache@v4
        with:
          path: ffmpeg-bin
          key: ffmpeg-bin-${{ runner.os }}-${{ hashFiles('.github/actions/setup-livecap-ffmpeg/action.yml') }}
          restore-keys: |
            ffmpeg-bin-${{ runner.os }}-

      - name: Setup LiveCap FFmpeg
        uses: ./.github/actions/setup-livecap-ffmpeg
        with:
          ffmpeg-bin-dir: 'ffmpeg-bin'

      - name: Sync dependencies
        run: uv sync --extra translation --extra dev --extra engines-torch

      - name: Run integration tests
        env:
          LIVECAP_FFMPEG_BIN: "${{ github.workspace }}/ffmpeg-bin"
        run: |
          uv run python -m pytest tests/integration -m "not engine_smoke"

  engine-smoke-cpu:
    runs-on: ubuntu-latest
    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Set up uv
        uses: astral-sh/setup-uv@v3

      - name: Cache ffmpeg-bin
        uses: actions/cache@v4
        with:
          path: ffmpeg-bin
          key: ffmpeg-bin-${{ runner.os }}-${{ hashFiles('.github/actions/setup-livecap-ffmpeg/action.yml') }}
          restore-keys: |
            ffmpeg-bin-${{ runner.os }}-

      - name: Setup LiveCap FFmpeg
        uses: ./.github/actions/setup-livecap-ffmpeg
        with:
          ffmpeg-bin-dir: 'ffmpeg-bin'

      - name: Sync dependencies
        run: uv sync --extra translation --extra dev --extra engines-torch

      - name: Warm engine caches (CPU)
        env:
          LIVECAP_FFMPEG_BIN: "${{ github.workspace }}/ffmpeg-bin"
        run: |
          uv run python - <<'PY'
          from engines.engine_factory import EngineFactory
          from livecap_core.config.defaults import get_default_config

          def warm(engine_type: str, device: str, lang: str) -> None:
              cfg = get_default_config()
              transcription = cfg["transcription"]
              transcription["engine"] = engine_type
              transcription["input_language"] = lang
              engine = EngineFactory.create_engine(
                  engine_type=engine_type,
                  device=device,
                  config=cfg,
              )
              engine.load_model()
              models_dir = engine.model_manager.get_models_dir(engine.engine_name)
              print(f"[{engine_type}/{device}] cached at: {models_dir}")

          warm("whispers2t_base", "cpu", "en")
          PY

      - name: Run engine smoke tests (CPU)
        env:
          LIVECAP_FFMPEG_BIN: "${{ github.workspace }}/ffmpeg-bin"
          LIVECAP_REQUIRE_ENGINE_SMOKE: ${{ vars.LIVECAP_REQUIRE_ENGINE_SMOKE }}
        run: |
          uv run python -m pytest tests/integration/engines -m "engine_smoke and not gpu"

  engine-smoke-gpu:
    if: vars.LIVECAP_ENABLE_GPU_SMOKE == '1'
    strategy:
      fail-fast: false
      matrix:
        os: [[self-hosted, linux], [self-hosted, windows]]

    runs-on: ${{ matrix.os }}

    env:
      LIVECAP_ENABLE_GPU_SMOKE: ${{ vars.LIVECAP_ENABLE_GPU_SMOKE }}
      LIVECAP_REQUIRE_ENGINE_SMOKE: ${{ vars.LIVECAP_REQUIRE_ENGINE_SMOKE }}

    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Configure Persistent Paths
        shell: bash
        run: |
          # Define base cache directory based on OS
          if [ "$RUNNER_OS" == "Windows" ]; then
             CACHE_ROOT="C:/LiveCap/Cache"
          else
             CACHE_ROOT="$HOME/LiveCap/Cache"
          fi
          
          # Ensure directories exist
          mkdir -p "$CACHE_ROOT/uv"
          mkdir -p "$CACHE_ROOT/models"
          mkdir -p "$CACHE_ROOT/huggingface"
          mkdir -p "$CACHE_ROOT/ffmpeg-bin"
          
          # Set Environment Variables for subsequent steps
          echo "UV_CACHE_DIR=$CACHE_ROOT/uv" >> $GITHUB_ENV
          echo "LIVECAP_CACHE_DIR=$CACHE_ROOT/models" >> $GITHUB_ENV
          echo "HF_HOME=$CACHE_ROOT/huggingface" >> $GITHUB_ENV
          echo "LIVECAP_FFMPEG_BIN=$CACHE_ROOT/ffmpeg-bin" >> $GITHUB_ENV
          
          echo "Configured persistent paths at $CACHE_ROOT"

      - name: Set up Python (Linux)
        if: runner.os == 'Linux'
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Use preinstalled Python (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          $python = Get-Command python3.12 | Select-Object -ExpandProperty Source
          if (-not $python) { throw "python3.12 not found on runner" }
          Write-Host "Using python at $python"
          "PYTHON_EXE=$python" | Out-File -FilePath $Env:GITHUB_ENV -Encoding utf8 -Append

      - name: Set up uv
        uses: astral-sh/setup-uv@v3

      # Removed actions/cache for ffmpeg-bin as we use persistent LIVECAP_FFMPEG_BIN

      - name: Check FFmpeg existence
        id: check-ffmpeg
        shell: bash
        run: |
          if [ -f "$LIVECAP_FFMPEG_BIN/ffmpeg" ] || [ -f "$LIVECAP_FFMPEG_BIN/ffmpeg.exe" ]; then
            echo "exists=true" >> $GITHUB_OUTPUT
            echo "FFmpeg found at $LIVECAP_FFMPEG_BIN"
          else
            echo "exists=false" >> $GITHUB_OUTPUT
            echo "FFmpeg not found, triggering setup"
          fi

      - name: Setup LiveCap FFmpeg
        if: steps.check-ffmpeg.outputs.exists != 'true'
        uses: ./.github/actions/setup-livecap-ffmpeg
        with:
          ffmpeg-bin-dir: ${{ env.LIVECAP_FFMPEG_BIN }}

      - name: Sync dependencies (Linux)
        if: runner.os == 'Linux'
        shell: bash
        run: |
          # Bypass lockfile sync
          rm -f uv.lock
          
          # Create venv and install dependencies manually
          uv venv
          # Install PyTorch from official index (cu124)
          uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
          # Install project dependencies
          uv pip install -e .[translation,dev,engines-torch,engines-nemo]
          # Remove conflicting cuDNN package
          uv pip uninstall nvidia-cudnn-cu12

      - name: Sync dependencies (Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        run: |
          # Reuse .venv if exists? No, for now keep clean slate but use cache
          # To optimize further, we could remove this Remove-Item line
          Remove-Item -Recurse -Force .venv -ErrorAction SilentlyContinue
          
          # Create venv explicitly
          uv python pin "$Env:PYTHON_EXE"
          uv venv
          
          # Add venv to PATH for subsequent steps
          echo "$PWD/.venv/Scripts" | Out-File -FilePath $env:GITHUB_PATH -Encoding utf8 -Append
          
          # 1. Install CUDA-enabled PyTorch FIRST
          uv pip install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124
          
          # 2. Install project dependencies using 'uv pip install'
          uv pip install -e .[translation,dev,engines-torch,engines-nemo]

      - name: Warm engine caches (GPU / self-hosted, Linux)
        if: runner.os == 'Linux'
        shell: bash
        # LIVECAP_FFMPEG_BIN is already set globally by Configure Persistent Paths
        run: |
          # Bypass lockfile sync
          .venv/bin/python - <<'PY'
          from engines.engine_factory import EngineFactory
          from livecap_core.config.defaults import get_default_config

          def warm(engine_type: str, device: str, lang: str) -> None:
              cfg = get_default_config()
              transcription = cfg["transcription"]
              transcription["engine"] = engine_type
              transcription["input_language"] = lang
              engine = EngineFactory.create_engine(
                  engine_type=engine_type,
                  device=device,
                  config=cfg,
              )
              engine.load_model()
              models_dir = engine.model_manager.get_models_dir(engine.engine_name)
              print(f"[{engine_type}/{device}] cached at: {models_dir}")

          # ReazonSpeech disabled on Linux due to ABI issues
          warm("whispers2t_base", "cuda", "en")
          warm("parakeet", "cuda", "en")
          PY

      - name: Warm engine caches (GPU / self-hosted, Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        # LIVECAP_FFMPEG_BIN is already set globally by Configure Persistent Paths
        run: |
          $script = @"
          import os
          import sys
          
          # Monkey-patch os.uname for Windows to satisfy lhotse dependency
          if sys.platform == "win32" and not hasattr(os, "uname"):
              from collections import namedtuple
              UnameResult = namedtuple("UnameResult", ["sysname", "nodename", "release", "version", "machine"])
              def uname():
                  # Avoid platform.* calls that might recurse back to os.uname
                  return UnameResult(
                      sysname="Windows",
                      nodename=os.environ.get("COMPUTERNAME", "unknown"),
                      release=os.environ.get("OS", "unknown"),
                      version="10.0.xxxx",
                      machine=os.environ.get("PROCESSOR_ARCHITECTURE", "AMD64")
                  )
              os.uname = uname

          from engines.engine_factory import EngineFactory
          from livecap_core.config.defaults import get_default_config

          def warm(engine_type: str, device: str, lang: str) -> None:
              cfg = get_default_config()
              transcription = cfg["transcription"]
              transcription["engine"] = engine_type
              transcription["input_language"] = lang
              engine = EngineFactory.create_engine(
                  engine_type=engine_type,
                  device=device,
                  config=cfg,
              )
              engine.load_model()
              models_dir = engine.model_manager.get_models_dir(engine.engine_name)
              print(f'[{engine_type}/{device}] cached at: {models_dir}')

          warm('reazonspeech', 'cuda', 'ja')
          warm('whispers2t_base', 'cuda', 'en')
          warm('parakeet', 'cuda', 'en')
          "@
          
          $script | Out-File warmup.py -Encoding utf8
          # Use python directly
          python warmup.py

      - name: Run engine smoke tests (GPU / self-hosted, Linux)
        if: runner.os == 'Linux'
        shell: bash
        env:
          # LIVECAP_FFMPEG_BIN set globally
          LIVECAP_ENABLE_GPU_SMOKE: ${{ vars.LIVECAP_ENABLE_GPU_SMOKE }}
          LIVECAP_REQUIRE_ENGINE_SMOKE: ${{ vars.LIVECAP_REQUIRE_ENGINE_SMOKE }}
        run: |
          # Skip ReazonSpeech on Linux GPU
          # Bypass lockfile sync
          .venv/bin/python -m pytest tests/integration/engines -m "engine_smoke and gpu" -k "not reazonspeech" -v

      - name: Run engine smoke tests (GPU / self-hosted, Windows)
        if: runner.os == 'Windows'
        shell: pwsh
        env:
          # LIVECAP_FFMPEG_BIN set globally
          LIVECAP_ENABLE_GPU_SMOKE: ${{ vars.LIVECAP_ENABLE_GPU_SMOKE }}
          LIVECAP_REQUIRE_ENGINE_SMOKE: ${{ vars.LIVECAP_REQUIRE_ENGINE_SMOKE }}
        run: |
          # Use python directly
          python -m pytest tests/integration/engines -m "engine_smoke and gpu" -v