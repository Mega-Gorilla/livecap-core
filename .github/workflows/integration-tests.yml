name: Integration Tests

on:
  workflow_dispatch:
  schedule:
    - cron: "0 3 * * 1"  # Weekly on Mondays at 03:00 UTC

jobs:
  transcription-pipeline:
    strategy:
      fail-fast: false
      matrix:
        # Include both hosted and self-hosted runners
        # Windows self-hosted is optional/experimental for now, so we can comment it out or keep it if ready.
        # Based on requirements, we enable self-hosted.
        os: [ubuntu-latest, [self-hosted, linux], [self-hosted, windows]]
        
    runs-on: ${{ matrix.os }}
    
    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python
        if: matrix.os == 'ubuntu-latest'
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Set up uv
        uses: astral-sh/setup-uv@v3

      - name: Cache ffmpeg-bin
        uses: actions/cache@v4
        with:
          path: ffmpeg-bin
          key: ffmpeg-bin-${{ runner.os }}-${{ hashFiles('.github/actions/setup-livecap-ffmpeg/action.yml') }}
          restore-keys: |
            ffmpeg-bin-${{ runner.os }}-

      - name: Setup LiveCap FFmpeg
        uses: ./.github/actions/setup-livecap-ffmpeg
        with:
          ffmpeg-bin-dir: 'ffmpeg-bin'

      - name: Sync dependencies
        run: uv sync --extra translation --extra dev --extra engines-torch

      - name: Run integration tests
        env:
          # Python handles forward slashes on all platforms
          LIVECAP_FFMPEG_BIN: "${{ github.workspace }}/ffmpeg-bin"
        run: |
          uv run python -m pytest tests/integration -m "not engine_smoke"

  engine-smoke-cpu:
    runs-on: ubuntu-latest
    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Set up uv
        uses: astral-sh/setup-uv@v3

      - name: Cache ffmpeg-bin
        uses: actions/cache@v4
        with:
          path: ffmpeg-bin
          key: ffmpeg-bin-${{ runner.os }}-${{ hashFiles('.github/actions/setup-livecap-ffmpeg/action.yml') }}
          restore-keys: |
            ffmpeg-bin-${{ runner.os }}-

      - name: Setup LiveCap FFmpeg
        uses: ./.github/actions/setup-livecap-ffmpeg
        with:
          ffmpeg-bin-dir: 'ffmpeg-bin'

      - name: Sync dependencies
        run: uv sync --extra translation --extra dev --extra engines-torch

      - name: Debug shared libraries
        run: |
          SITE_PACKAGES=$(uv run python -c "import site; print(site.getsitepackages()[0])")
          SHERPA_LIB="$SITE_PACKAGES/sherpa_onnx/lib"
          
          echo "Listing $SHERPA_LIB:"
          ls -l "$SHERPA_LIB" || echo "Directory not found"
          
          echo "Checking dependencies of _sherpa_onnx extension:"
          EXT_MOD=$(find "$SITE_PACKAGES/sherpa_onnx" -name "_sherpa_onnx*.so" | head -n 1)
          if [ -n "$EXT_MOD" ]; then
            echo "Target: $EXT_MOD"
            ldd "$EXT_MOD"
          else
            echo "Extension module not found!"
          fi

      - name: Warm engine caches (CPU)
        env:
          LIVECAP_FFMPEG_BIN: "${{ github.workspace }}/ffmpeg-bin"
        run: |
          # Bypass 'uv run' to avoid lockfile reversion. Use the venv directly.
          # Assuming .venv exists in project root (standard uv behavior)
          VENV_PYTHON=".venv/bin/python"
          if [ ! -f "$VENV_PYTHON" ]; then
             # Fallback if venv is elsewhere (e.g. windows or custom setup)
             VENV_PYTHON=$(uv run which python)
          fi
          
          echo "Using Python at: $VENV_PYTHON"
          
          # Force install compatible onnxruntime into this venv
          echo "Forcing onnxruntime==1.17.1..."
          uv pip install --python "$VENV_PYTHON" onnxruntime==1.17.1
          
          # Run the warmup script using the direct python path
          "$VENV_PYTHON" - <<'PY'
          import os
          import sys
          import site
          import pathlib
          import onnxruntime
          import ctypes
          
          print(f"Runtime ORT version: {onnxruntime.__version__}")
          
          # --- Dynamic Library Fix ---
          # Locate ORT package dir
          ort_pkg_dir = pathlib.Path(onnxruntime.__file__).parent
          print(f"ORT package dir: {ort_pkg_dir}")
          
          # Look for library in 'capi' (standard location) or root
          candidates = list(ort_pkg_dir.glob("capi/libonnxruntime.so*")) + list(ort_pkg_dir.glob("libonnxruntime.so*"))
          lib_path = next((p for p in candidates if p.is_file() and "providers" not in p.name), None)
          
          if lib_path:
              lib_dir = lib_path.parent
              print(f"Found ORT lib at: {lib_path}")
              
              # Create symlink 'libonnxruntime.so' if missing
              link_path = lib_dir / "libonnxruntime.so"
              if not link_path.exists():
                  print(f"Creating symlink: {link_path} -> {lib_path.name}")
                  try:
                      link_path.symlink_to(lib_path.name)
                  except OSError as e:
                      print(f"Symlink creation failed: {e}")
              
              # Preload with ctypes using RTLD_GLOBAL to ensure visibility to sherpa-onnx
              try:
                  print(f"Pre-loading shared library with RTLD_GLOBAL: {link_path}")
                  ctypes.CDLL(str(link_path), mode=ctypes.RTLD_GLOBAL)
              except Exception as e:
                  print(f"Failed to pre-load library: {e}")
          else:
              print("WARNING: Could not find libonnxruntime.so in onnxruntime package")

          # --- Warmup ---
          from engines.engine_factory import EngineFactory
          from livecap_core.config.defaults import get_default_config

          def warm(engine_type: str, device: str, lang: str) -> None:
              cfg = get_default_config()
              transcription = cfg["transcription"]
              transcription["engine"] = engine_type
              transcription["input_language"] = lang
              engine = EngineFactory.create_engine(
                  engine_type=engine_type,
                  device=device,
                  config=cfg,
              )
              engine.load_model()
              models_dir = engine.model_manager.get_models_dir(engine.engine_name)
              print(f"[{engine_type}/{device}] cached at: {models_dir}")

          warm("reazonspeech", "cpu", "ja")
          warm("whispers2t_base", "cpu", "en")
          PY

      - name: Run engine smoke tests (CPU)
        env:
          LIVECAP_FFMPEG_BIN: "${{ github.workspace }}/ffmpeg-bin"
          LIVECAP_REQUIRE_ENGINE_SMOKE: ${{ vars.LIVECAP_REQUIRE_ENGINE_SMOKE }}
        run: |
          uv run python -m pytest tests/integration/engines -m "engine_smoke and not gpu"

  engine-smoke-gpu:
    if: vars.LIVECAP_ENABLE_GPU_SMOKE == '1'
    strategy:
      fail-fast: false
      matrix:
        os: [[self-hosted, linux], [self-hosted, windows]]

    runs-on: ${{ matrix.os }}

    env:
      LIVECAP_ENABLE_GPU_SMOKE: ${{ vars.LIVECAP_ENABLE_GPU_SMOKE }}
      LIVECAP_REQUIRE_ENGINE_SMOKE: ${{ vars.LIVECAP_REQUIRE_ENGINE_SMOKE }}

    steps:
      - name: Check out repository
        uses: actions/checkout@v4

      - name: Set up Python (Linux)
        if: matrix.os == '[self-hosted, linux]'
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Use preinstalled Python (Windows)
        if: matrix.os == '[self-hosted, windows]'
        shell: pwsh
        run: |
          $python = Get-Command python3.12 | Select-Object -ExpandProperty Source
          if (-not $python) { throw "python3.12 not found on runner" }
          Write-Host "Using python at $python"
          "PYTHON_EXE=$python" | Out-File -FilePath $Env:GITHUB_ENV -Encoding utf8 -Append

      - name: Set up uv
        uses: astral-sh/setup-uv@v3

      - name: Cache ffmpeg-bin
        uses: actions/cache@v4
        with:
          path: ffmpeg-bin
          key: ffmpeg-bin-${{ runner.os }}-${{ hashFiles('.github/actions/setup-livecap-ffmpeg/action.yml') }}
          restore-keys: |
            ffmpeg-bin-${{ runner.os }}-

      - name: Setup LiveCap FFmpeg
        uses: ./.github/actions/setup-livecap-ffmpeg
        with:
          ffmpeg-bin-dir: 'ffmpeg-bin'

      - name: Sync dependencies (Linux)
        if: matrix.os == '[self-hosted, linux]'
        shell: bash
        run: |
          uv sync --extra translation --extra dev --extra engines-torch --extra engines-nemo

      - name: Sync dependencies (Windows)
        if: matrix.os == '[self-hosted, windows]'
        shell: pwsh
        run: |
          uv python pin "$Env:PYTHON_EXE"
          uv sync --extra translation --extra dev --extra engines-torch --extra engines-nemo

      - name: Warm engine caches (GPU / self-hosted, Linux)
        if: matrix.os == '[self-hosted, linux]'
        shell: bash
        env:
          LIVECAP_FFMPEG_BIN: "${{ github.workspace }}/ffmpeg-bin"
        run: |
          uv run python - <<'PY'
          from engines.engine_factory import EngineFactory
          from livecap_core.config.defaults import get_default_config

          def warm(engine_type: str, device: str, lang: str) -> None:
              cfg = get_default_config()
              transcription = cfg["transcription"]
              transcription["engine"] = engine_type
              transcription["input_language"] = lang
              engine = EngineFactory.create_engine(
                  engine_type=engine_type,
                  device=device,
                  config=cfg,
              )
              engine.load_model()
              models_dir = engine.model_manager.get_models_dir(engine.engine_name)
              print(f"[{engine_type}/{device}] cached at: {models_dir}")

          warm("whispers2t_base", "cuda", "en")
          warm("parakeet", "cuda", "en")
          PY

      - name: Warm engine caches (GPU / self-hosted, Windows)
        if: matrix.os == '[self-hosted, windows]'
        shell: pwsh
        env:
          LIVECAP_FFMPEG_BIN: "${{ github.workspace }}/ffmpeg-bin"
        run: |
          uv python pin "$Env:PYTHON_EXE"
          uv run python - <<'PY'
          from engines.engine_factory import EngineFactory
          from livecap_core.config.defaults import get_default_config

          def warm(engine_type: str, device: str, lang: str) -> None:
              cfg = get_default_config()
              transcription = cfg["transcription"]
              transcription["engine"] = engine_type
              transcription["input_language"] = lang
              engine = EngineFactory.create_engine(
                  engine_type=engine_type,
                  device=device,
                  config=cfg,
              )
              engine.load_model()
              models_dir = engine.model_manager.get_models_dir(engine.engine_name)
              print(f"[{engine_type}/{device}] cached at: {models_dir}")

          warm("whispers2t_base", "cuda", "en")
          warm("parakeet", "cuda", "en")
          PY

      - name: Run engine smoke tests (GPU / self-hosted, Linux)
        if: matrix.os == '[self-hosted, linux]'
        shell: bash
        env:
          LIVECAP_FFMPEG_BIN: "${{ github.workspace }}/ffmpeg-bin"
          LIVECAP_ENABLE_GPU_SMOKE: ${{ vars.LIVECAP_ENABLE_GPU_SMOKE }}
          LIVECAP_REQUIRE_ENGINE_SMOKE: ${{ vars.LIVECAP_REQUIRE_ENGINE_SMOKE }}
        run: |
          uv run python -m pytest tests/integration/engines -m "engine_smoke and gpu"

      - name: Run engine smoke tests (GPU / self-hosted, Windows)
        if: matrix.os == '[self-hosted, windows]'
        shell: pwsh
        env:
          LIVECAP_FFMPEG_BIN: "${{ github.workspace }}/ffmpeg-bin"
          LIVECAP_ENABLE_GPU_SMOKE: ${{ vars.LIVECAP_ENABLE_GPU_SMOKE }}
          LIVECAP_REQUIRE_ENGINE_SMOKE: ${{ vars.LIVECAP_REQUIRE_ENGINE_SMOKE }}
        run: |
          uv python pin "$Env:PYTHON_EXE"
          uv run python -m pytest tests/integration/engines -m "engine_smoke and gpu"
